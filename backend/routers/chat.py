"""
ğŸ§  Ù…ÙÙÙÙˆÙ’ØªÙØ± | Smart Invoice Analyzer - AI Chat System
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ù†Ø¸Ø§Ù… Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªÙƒØ§Ù…Ù„ Ù„Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙˆØ§ØªÙŠØ±.

Ø§Ù„Ù…Ø±Ø§Ø­Ù„:
1. Refiner Stage    - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„ Ù…Ù† Ø¹Ø§Ù…ÙŠØ© Ø¥Ù„Ù‰ ÙØµØ­Ù‰
2. Router Stage     - ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (deep_sql, rag, hybrid, none)
3. Executor Stage   - ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ù„Ø¨Ø­Ø«
4. Validator Stage  - Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
5. Replier Stage    - ØµÙŠØ§ØºØ© Ø§Ù„Ø±Ø¯ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ

Ø§Ù„Ø£Ù…Ø§Ù†:
- ÙÙ‚Ø· Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª SELECT Ù…Ø³Ù…ÙˆØ­Ø©
- ØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„ Ø§Ø³ØªØ¹Ù„Ø§Ù… SQL Ù‚Ø¨Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°
- Ø­Ù…Ø§ÙŠØ© Ù…Ù† SQL Injection

Ø§Ù„Ø³ÙŠØ§Ù‚:
- Ø­ÙØ¸ Ø¢Ø®Ø± 3 Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…
- Ø±Ø¨Ø· Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ø§Ù„Ù…Ø­Ù„Ù„Ø© Ù…Ù† VLM
- Ø¯Ø¹Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© (follow-up questions)
"""

from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from sqlalchemy.orm import Session
from sqlalchemy import text
from openai import OpenAI
import os
import json
import re
import logging
import numpy as np
from datetime import datetime, date
from decimal import Decimal
from typing import Optional, List, Dict, Any, Literal
from backend.database import get_db

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”§ Configuration & Setup
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

router = APIRouter(prefix="/chat", tags=["Chat"])
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Models Configuration
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
LLM_MODEL = os.getenv("LLM_MODEL", "gpt-4o-mini")

# Database Configuration
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_BUCKET = os.getenv("SUPABASE_BUCKET", "invoices")

# Logger Setup
logger = logging.getLogger("backend.chat")
logger.setLevel(logging.INFO)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š Global Context Management
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ChatContext:
    """Global context to remember user's conversation history"""
    
    def __init__(self):
        self.last_3_intents: List[str] = []
        self.last_3_invoices: List[Dict] = []
        self.last_3_modes: List[str] = []
    
    def add_context(self, intent: str, invoices: List[Dict], mode: str):
        """Add new context and maintain only last 3"""
        self.last_3_intents.insert(0, intent)
        self.last_3_invoices.insert(0, invoices)
        self.last_3_modes.insert(0, mode)
        
        # Keep only last 3
        self.last_3_intents = self.last_3_intents[:3]
        self.last_3_invoices = self.last_3_invoices[:3]
        self.last_3_modes = self.last_3_modes[:3]
    
    def get_last_invoices(self) -> List[Dict]:
        """Get last shown invoices"""
        return self.last_3_invoices[0] if self.last_3_invoices else []
    
    def get_last_intent(self) -> Optional[str]:
        """Get last user intent"""
        return self.last_3_intents[0] if self.last_3_intents else None
    
    def clear(self):
        """Clear all context"""
        self.last_3_intents.clear()
        self.last_3_invoices.clear()
        self.last_3_modes.clear()

# Global context instance
context = ChatContext()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ› ï¸ Utility Functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def serialize_for_json(obj: Any) -> Any:
    """Convert datetime, Decimal, and other types to JSON-serializable format"""
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    elif isinstance(obj, Decimal):
        return float(obj)
    elif isinstance(obj, dict):
        return {k: serialize_for_json(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [serialize_for_json(item) for item in obj]
    else:
        return obj


def format_invoice_for_frontend(invoice_data: dict) -> dict:
    """Format invoice data for frontend display with guaranteed image_url"""
    formatted = {
        "id": invoice_data.get("id"),
        "vendor": invoice_data.get("vendor") or "Ù…ØªØ¬Ø± ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ",
        "invoice_number": invoice_data.get("invoice_number"),
        "invoice_type": invoice_data.get("invoice_type"),
        "date": invoice_data.get("invoice_date") or invoice_data.get("date"),
        "total": str(invoice_data.get("total_amount") or invoice_data.get("total") or "0"),
        "tax": str(invoice_data.get("tax") or "0"),
        "payment_method": invoice_data.get("payment_method"),
        "image_url": invoice_data.get("image_url") or "",
        "category": invoice_data.get("category"),
        "ai_insight": invoice_data.get("ai_insight"),
    }
    
    if formatted["image_url"]:
        logger.debug(f"ğŸ–¼ï¸ Invoice {formatted['id']} | Vendor: {formatted['vendor']} | Has Image: âœ…")
    else:
        logger.warning(f"âš ï¸ Invoice {formatted['id']} | Vendor: {formatted['vendor']} | No Image URL")
    
    return formatted


def is_safe_sql(sql_query: str) -> bool:
    """
    Check if SQL query is safe (only SELECT allowed)
    Returns True if safe, False otherwise
    """
    sql_lower = sql_query.lower().strip()
    
    # Must start with SELECT
    if not sql_lower.startswith("select"):
        logger.warning(f"ğŸš« Unsafe SQL: Does not start with SELECT")
        return False
    
    # Forbidden keywords
    forbidden = ["delete", "drop", "truncate", "update", "insert", "alter", "create", "exec", "execute"]
    for word in forbidden:
        if word in sql_lower:
            logger.warning(f"ğŸš« Unsafe SQL: Contains forbidden keyword '{word}'")
            return False
    
    logger.info(f"âœ… SQL is safe: {sql_query[:100]}...")
    return True


def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """Calculate cosine similarity between two vectors"""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    return dot_product / (norm1 * norm2)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§© STAGE 1: Refiner
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def refine_user_query(user_query: str) -> str:
    """
    ğŸ” Refiner Stage:
    ØªØ­Ø³ÙŠÙ† ÙˆØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø¹Ø§Ù…ÙŠØ© Ø¥Ù„Ù‰ ÙØµØ­Ù‰ ÙˆØ§Ø¶Ø­Ø©
    
    Args:
        user_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    
    Returns:
        Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ø¨Ø§Ù„ÙØµØ­Ù‰
    """
    logger.info("ğŸ” Starting Refiner Stage...")
    logger.info(f"   Original Query: {user_query}")
    
    try:
        refiner_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

**Ù…Ù‡Ù…ØªÙƒ:**
Ø­ÙˆÙ‘Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© (Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©/Ø§Ù„Ø®Ù„ÙŠØ¬ÙŠØ©) Ø¥Ù„Ù‰ Ù„ØºØ© Ø¹Ø±Ø¨ÙŠØ© ÙØµØ­Ù‰ ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©.

**Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:**
1. Ù„Ø§ ØªØºÙŠÙ‘Ø± Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ùˆ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„
2. Ù„Ø§ ØªØ¶Ù Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
3. ÙÙ‚Ø· Ù†Ø¸Ù‘Ù Ø§Ù„Ù„Ù‡Ø¬Ø© ÙˆØ­Ø³Ù‘Ù† Ø§Ù„ØµÙŠØ§ØºØ©
4. **Ø§Ø­ØªÙØ¸ Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© ÙƒÙ…Ø§ Ù‡ÙŠ EXACTLY** (Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ØªØ§Ø¬Ø± Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…ØŒ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®)
   - Ù…Ø«Ø§Ù„: "Keeta" â†’ Ø£Ø¨Ù‚ÙÙ‡Ø§ "Keeta" (Ù„Ø§ ØªØºÙŠØ±Ù‡Ø§)
   - Ù…Ø«Ø§Ù„: "ÙƒØªØ§" â†’ Ø£Ø¨Ù‚ÙÙ‡Ø§ "ÙƒØªØ§"
5. **Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù… Ø§Ù„Ù…ØªØ¬Ø± Ø·ÙˆÙŠÙ„ØŒ Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø·**
   - Ù…Ø«Ø§Ù„: "Ø´Ø±ÙƒØ© Ø¬ÙŠØ±Ø© Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø´Ø±ÙˆØ¨Ø§Øª - ÙØ±Ø¹ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©" â†’ "ÙØ§ØªÙˆØ±Ø© Ø¬ÙŠØ±Ø©"
   - Ù…Ø«Ø§Ù„: "Ù…Ø¤Ø³Ø³Ø© ØµØ¨ ÙˆØ§ÙŠ Ù„Ù„Ø£ØºØ°ÙŠØ©" â†’ "ÙØ§ØªÙˆØ±Ø© ØµØ¨ ÙˆØ§ÙŠ"
   - Ù…Ø«Ø§Ù„: "Keeta Restaurant" â†’ "ÙØ§ØªÙˆØ±Ø© Keeta"
6. Ø£Ø®Ø±Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø­Ø³Ù‘Ù† ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­ Ø£Ùˆ ØªØ¹Ù„ÙŠÙ‚

**Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ØµÙ„ÙŠ:**
"{user_query}"

**Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†:**
"""
        
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. ØªØ­ÙˆÙ‘Ù„ Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ø¹Ø§Ù…ÙŠØ© Ø¥Ù„Ù‰ ÙØµØ­Ù‰ Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ø§Ù„Ù…Ø¹Ù†Ù‰."},
                {"role": "user", "content": refiner_prompt}
            ],
            temperature=0.3,
            max_tokens=200
        )
        
        refined_query = response.choices[0].message.content.strip()
        
        # Remove any quotes or extra formatting
        refined_query = refined_query.strip('"').strip("'").strip()
        
        logger.info(f"âœ… Refined Query: {refined_query}")
        return refined_query
        
    except Exception as e:
        logger.error(f"âŒ Refiner Stage failed: {e}")
        # If refiner fails, return original query
        return user_query

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§­ STAGE 2: Router
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class RouterDecision(BaseModel):
    """Router decision model"""
    mode: Literal["deep_sql", "rag", "hybrid", "none"]
    reason: str
    show_images: bool = False
    requested_vendor: Optional[str] = None


def route_query(refined_query: str) -> RouterDecision:
    """
    ğŸ§­ Router Stage:
    ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
    
    Args:
        refined_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ù…Ù† Refiner
    
    Returns:
        RouterDecision object with mode and reason
    """
    logger.info("ğŸ§­ Starting Router Stage...")
    logger.info(f"   Query: {refined_query}")
    
    try:
        router_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„ÙÙˆØ§ØªÙŠØ±.

**Ù…Ù‡Ù…ØªÙƒ:**
Ø­Ø¯Ø¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ:

**Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:**

1. **deep_sql** - Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ© ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©:
   - ÙƒÙ… Ø¹Ø¯Ø¯ØŸ ÙƒÙ… Ø¥Ø¬Ù…Ø§Ù„ÙŠØŸ ÙƒÙ… Ù…Ø¬Ù…ÙˆØ¹ØŸ
   - Ø£Ø¹Ù„Ù‰ØŒ Ø£Ù‚Ù„ØŒ Ø£ÙƒØ«Ø±ØŒ Ø£Ù‚Ù„
   - Ù…ØªÙˆØ³Ø·ØŒ Ù…Ø¹Ø¯Ù„
   - Ù…Ø«Ø§Ù„: "ÙƒÙ… Ø¹Ø¯Ø¯ ÙÙˆØ§ØªÙŠØ±ÙŠØŸ" "Ù…Ø§ Ø£Ø¹Ù„Ù‰ ÙØ§ØªÙˆØ±Ø©ØŸ"

2. **rag** - Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø¹Ù†ÙˆÙŠØ© ÙˆØ§Ù„Ù†ØµÙŠØ©:
   - Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…ØªØ¬Ø± Ù…Ø¹ÙŠÙ†
   - ÙØ§ØªÙˆØ±Ø© Ø¨Ù†ÙˆØ¹ Ù…Ø¹ÙŠÙ† (Ù…Ø·Ø¹Ù…ØŒ ØµÙŠØ¯Ù„ÙŠØ©ØŒ ÙƒØ§ÙÙŠÙ‡)
   - Ø·Ù„Ø¨Ø§Øª Ø§Ù„ØµÙˆØ± (ØµÙˆØ±Ø© ÙØ§ØªÙˆØ±Ø©ØŒ ÙˆØ±Ù‘Ù†ÙŠ ØµÙˆØ±Ø©ØŒ Ø£Ø±ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©ØŒ invoice image)
   - Ù…Ø«Ø§Ù„: "Ø§Ø¨ÙŠ ÙØ§ØªÙˆØ±Ø© ØµØ¨ ÙˆØ§ÙŠ" "ÙˆØ±ÙŠÙ†ÙŠ ÙØ§ØªÙˆØ±Ø© Ø§Ù„Ù…Ø·Ø¹Ù…" "ØµÙˆØ±Ø© ÙØ§ØªÙˆØ±Ø© ÙƒØªØ§"

3. **hybrid** - Ù„Ù„Ø¬Ù…Ø¹ Ø¨ÙŠÙ† SQL ÙˆØ§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ:
   - Ø£Ø³Ø¦Ù„Ø© ØªØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ
   - Ù…Ø«Ø§Ù„: "Ø£Ø¹Ù„Ù‰ ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ø§Ù„Ù…Ø·Ø§Ø¹Ù…" "ÙƒÙ… ÙØ§ØªÙˆØ±Ø© Ø¹Ù†Ø¯ÙŠ Ù…Ù† Ø§Ù„ØµÙŠØ¯Ù„ÙŠØ§Øª"

4. **none** - Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø®Ø§Ø±Ø¬ Ù†Ø·Ø§Ù‚ Ø§Ù„ÙÙˆØ§ØªÙŠØ±:
   - Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø© ØºÙŠØ± Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„ÙÙˆØ§ØªÙŠØ±
   - Ù…Ø«Ø§Ù„: "ÙˆØ´ Ø§Ù„Ø·Ù‚Ø³ Ø§Ù„ÙŠÙˆÙ…ØŸ" "ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ"

**Ø¥Ø¶Ø§ÙÙŠ:**
- **show_images**: Ø§Ø¬Ø¹Ù„Ù‡Ø§ true ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø§Øª:
  * ØµÙˆØ±Ø© Ø£Ùˆ ØµÙˆØ± (image/images) 
  * ÙˆØ±Ù‘Ù†ÙŠØŒ Ø´ÙˆÙÙ†ÙŠØŒ Ø£Ø±ÙŠØ¯ Ø£Ù† Ø£Ø±Ù‰ØŒ Ø§Ø¨ÙŠ
  * ÙØ§ØªÙˆØ±Ø© Ù…Ù† Ù…ØªØ¬Ø± Ù…Ø­Ø¯Ø¯ (Ù…Ø«Ù„Ø§Ù‹: "ÙØ§ØªÙˆØ±Ø© ÙƒØªØ§" "ÙØ§ØªÙˆØ±Ø© ØµØ¨ ÙˆØ§ÙŠ" "ÙØ§ØªÙˆØ±Ø© Ù…Ø·Ø¹Ù…")
  * Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø¹Ù† ÙØ§ØªÙˆØ±Ø© Ù…Ø¹ÙŠÙ†Ø© (Ø§Ø³Ù… Ù…ØªØ¬Ø±ØŒ Ù†ÙˆØ¹ Ù…ØªØ¬Ø±ØŒ ÙØ±Ø¹)
  * **Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ Ø§Ø¬Ø¹Ù„Ù‡Ø§ true Ø¥Ù„Ø§ Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© ÙÙ‚Ø·** (ÙƒÙ… Ø¹Ø¯Ø¯ØŒ ÙƒÙ… Ù…Ø¬Ù…ÙˆØ¹)
- **requested_vendor**: Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…ØªØ¬Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø·:
  * Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§Ø³Ù… Ø·ÙˆÙŠÙ„ (Ù…Ø«Ù„: "Ø´Ø±ÙƒØ© Ø¬ÙŠØ±Ø© Ù„ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø´Ø±ÙˆØ¨Ø§Øª - ÙØ±Ø¹ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠØ©") â†’ Ø£ÙƒØªØ¨ "Ø¬ÙŠØ±Ø©"
  * Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨Ø³ÙŠØ· (Ù…Ø«Ù„: "ÙƒØªØ§") â†’ Ø£ÙƒØªØ¨ "ÙƒØªØ§"
  * Ø£Ù…Ø«Ù„Ø©: ÙƒØªØ§ØŒ ØµØ¨ ÙˆØ§ÙŠØŒ Ø¬Ø±ÙŠØ±ØŒ Ø¨Ù†Ø¯Ù‡ØŒ Ø¬ÙŠØ±Ø©ØŒ Ø§Ù„Ø¯Ø§Ù†ÙˆØ¨ØŒ etc.

**Ø§Ù„Ø³Ø¤Ø§Ù„:**
"{refined_query}"

**Ø£Ø®Ø±Ø¬ JSON ÙÙ‚Ø· Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:**
{{
  "mode": "deep_sql" Ø£Ùˆ "rag" Ø£Ùˆ "hybrid" Ø£Ùˆ "none",
  "reason": "Ø´Ø±Ø­ Ù‚ØµÙŠØ± Ù„Ù„Ø³Ø¨Ø¨",
  "show_images": true Ø£Ùˆ false,
  "requested_vendor": "Ø§Ø³Ù… Ø§Ù„Ù…ØªØ¬Ø±" Ø£Ùˆ null
}}
"""
        
        response = client.chat.completions.create(
            model=LLM_MODEL,
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©. Ø£Ø®Ø±Ø¬ JSON ÙÙ‚Ø·."},
                {"role": "user", "content": router_prompt}
            ],
            temperature=0.2,
            max_tokens=300
        )
        
        router_output = response.choices[0].message.content.strip()
        
        # Extract JSON from response
        json_match = re.search(r'\{.*\}', router_output, re.DOTALL)
        if json_match:
            router_json = json.loads(json_match.group())
        else:
            router_json = json.loads(router_output)
        
        decision = RouterDecision(
            mode=router_json.get("mode", "none"),
            reason=router_json.get("reason", ""),
            show_images=router_json.get("show_images", False),
            requested_vendor=router_json.get("requested_vendor")
        )
        
        logger.info(f"âœ… Router Decision: {decision.mode}")
        logger.info(f"   Reason: {decision.reason}")
        logger.info(f"   Show Images: {decision.show_images}")
        if decision.requested_vendor:
            logger.info(f"   Requested Vendor: {decision.requested_vendor}")
        
        return decision
        
    except Exception as e:
        logger.error(f"âŒ Router Stage failed: {e}")
        # Default to hybrid mode if router fails
        return RouterDecision(
            mode="hybrid",
            reason=f"Router failed, defaulting to hybrid: {str(e)}"
        )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ§® STAGE 3: Executor
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def execute_deep_sql(refined_query: str, db: Session) -> List[Dict]:
    """
    ğŸ§® Execute deep SQL query for analytical questions
    
    Args:
        refined_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
        db: Database session
    
    Returns:
        List of results from database
    """
    logger.info("ğŸ§® Executing Deep SQL...")
    
    try:
        # Generate SQL query using AI
        sql_prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª SQL Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙÙˆØ§ØªÙŠØ±.

**Ø¬Ø¯ÙˆÙ„ Ø§Ù„ÙÙˆØ§ØªÙŠØ± (invoices):**
- id (integer)
- invoice_number (varchar)
- invoice_date (timestamp)
- vendor (varchar) - Ø§Ø³Ù… Ø§Ù„Ù…ØªØ¬Ø±
- tax_number (varchar)
- cashier (varchar)
- branch (varchar)
- phone (varchar)
- subtotal (varchar)
- tax (varchar)
- total_amount (varchar) - Ø§Ù„Ù…Ø¨Ù„Øº Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
- discounts (varchar)
- payment_method (varchar)
- category (varchar)
- invoice_type (text)
- ai_insight (text)
- image_url (text)
- is_valid_invoice (boolean)
- created_at (timestamp)

**Ø§Ù„Ø³Ø¤Ø§Ù„:**
"{refined_query}"

**Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:**
1. Ø§Ø³ØªØ¹Ù„Ø§Ù… SELECT ÙÙ‚Ø· (Ù…Ù…Ù†ÙˆØ¹ DELETE, UPDATE, INSERT)
2. Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØµØ­ÙŠØ­Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¹Ù„Ø§Ù‡
3. total_amount Ù‡Ùˆ varcharØŒ Ø§Ø³ØªØ®Ø¯Ù… CAST Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ø±Ù‚Ù… Ø¥Ø°Ø§ Ù„Ø²Ù…
4. Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†ØµØŒ Ø§Ø³ØªØ®Ø¯Ù… ILIKE Ù…Ø¹ %
5. Ø£Ø®Ø±Ø¬ SQL ÙÙ‚Ø·ØŒ Ø¨Ø¯ÙˆÙ† Ø´Ø±Ø­

**Ù…Ø«Ø§Ù„:**
Ø³Ø¤Ø§Ù„: "ÙƒÙ… Ø¹Ø¯Ø¯ ÙÙˆØ§ØªÙŠØ±ÙŠØŸ"
SQL: SELECT COUNT(*) as count FROM invoices WHERE is_valid_invoice = true

Ø³Ø¤Ø§Ù„: "Ù…Ø§ Ø£Ø¹Ù„Ù‰ ÙØ§ØªÙˆØ±Ø©ØŸ"
SQL: SELECT * FROM invoices WHERE is_valid_invoice = true ORDER BY CAST(total_amount AS DECIMAL) DESC LIMIT 1

**SQL Query:**
"""
        
        response = client.chat.completions.create(
            model=LLM_MODEL,
                messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± SQL. Ø£Ø®Ø±Ø¬ SQL ÙÙ‚Ø·."},
                {"role": "user", "content": sql_prompt}
            ],
            temperature=0.1,
            max_tokens=500
        )
        
        sql_query = response.choices[0].message.content.strip()
        
        # Clean SQL query
        sql_query = sql_query.strip('```sql').strip('```').strip()
        
        logger.info(f"ğŸ“Š Generated SQL: {sql_query}")
        
        # Safety check
        if not is_safe_sql(sql_query):
            logger.error("ğŸš« Unsafe SQL query rejected")
            return []
        
        # Execute SQL
        rows = db.execute(text(sql_query)).fetchall()
        results = [serialize_for_json(dict(row._mapping)) for row in rows]
        
        logger.info(f"âœ… SQL returned {len(results)} results")
        return results
        
    except Exception as e:
        logger.error(f"âŒ Deep SQL execution failed: {e}")
        return []


def execute_rag(refined_query: str, db: Session, top_k: int = 5) -> List[Dict]:
    """
    ğŸ” Execute RAG (Retrieval-Augmented Generation) using embeddings
    
    Args:
        refined_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
        db: Database session
        top_k: Number of top results to return
    
    Returns:
        List of semantically similar invoices
    """
    logger.info("ğŸ” Executing RAG (Semantic Search with embeddings)...")
    
    try:
        # Generate embedding for user query
        embedding_response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=refined_query
        )
        
        query_embedding = np.array(embedding_response.data[0].embedding)
        logger.info(f"âœ… Generated query embedding (dim: {len(query_embedding)})")
        
        # Get all invoices with embeddings - CORRECT TABLE NAME!
        sql = text("""
            SELECT i.*, e.embedding
            FROM invoices i
            LEFT JOIN invoice_embeddings e ON i.id = e.invoice_id
            WHERE i.is_valid_invoice = true
            AND e.embedding IS NOT NULL
            AND i.image_url IS NOT NULL
        """)
        
        rows = db.execute(sql).fetchall()
        logger.info(f"ğŸ“Š Found {len(rows)} invoices with embeddings")
        
        if not rows:
            logger.warning("âš ï¸ No invoices with embeddings found")
            return []
        
        # Calculate similarities using pgvector
        similarities = []
        for row in rows:
            row_dict = dict(row._mapping)
            
            # Parse embedding (pgvector returns it as a list)
            embedding_data = row_dict.get('embedding')
            if not embedding_data:
                continue
            
            try:
                # Convert to numpy array if it's a list
                if isinstance(embedding_data, list):
                    invoice_embedding = np.array(embedding_data)
                elif isinstance(embedding_data, str):
                    invoice_embedding = np.array(json.loads(embedding_data))
                else:
                    invoice_embedding = np.array(embedding_data)
                
                similarity = cosine_similarity(query_embedding, invoice_embedding)
                
                similarities.append({
                    'invoice': row_dict,
                    'similarity': float(similarity)
                })
            except Exception as e:
                logger.debug(f"Failed to process embedding for invoice {row_dict.get('id')}: {e}")
                continue
        
        # Sort by similarity and get top_k
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        top_results = similarities[:top_k]
        
        results = [item['invoice'] for item in top_results]
        
        logger.info(f"âœ… RAG returned {len(results)} results")
        for i, item in enumerate(top_results[:3], 1):
            logger.info(f"   {i}. {item['invoice'].get('vendor', 'Unknown')} (similarity: {item['similarity']:.3f})")
        
        return results
    
    except Exception as e:
        logger.error(f"âŒ RAG execution failed: {e}")
        
        # Rollback the failed transaction first
        try:
            db.rollback()
            logger.info("ğŸ”„ Transaction rolled back after RAG failure")
        except Exception as rollback_error:
            logger.warning(f"âš ï¸ Rollback warning: {rollback_error}")
        
        # Fallback: Super flexible SQL search (NO embeddings table)
        try:
            logger.info("ğŸ”„ Falling back to Basic SQL search (no embeddings)...")
            
            # Clean keywords - remove ALL Arabic filter words
            keywords = (refined_query
                       .replace("ÙØ§ØªÙˆØ±Ø©", "")
                       .replace("ØµÙˆØ±Ø©", "")
                       .replace("Ø§Ø¨ÙŠ", "")
                       .replace("ÙˆØ±ÙŠÙ†ÙŠ", "")
                       .replace("Ù…Ø·Ø¹Ù…", "")
                       .replace("Ù…ØªØ¬Ø±", "")
                       .replace("Ù…Ù†", "")
                       .replace("ÙÙŠ", "")
                       .replace("Ø£Ø±ÙŠØ¯", "")
                       .replace("ÙƒÙ…", "")
                       .replace("Ø£Ù†ÙÙ‚Øª", "")
                       .replace("Ø¹Ù„Ù‰", "")
                       .replace("ØŸ", "")
                       .strip())
            
            logger.info(f"ğŸ” Original query: '{refined_query}'")
            logger.info(f"ğŸ” Extracted keywords: '{keywords}'")
            
            # If still empty after cleaning, try to get ALL invoices with images
            if not keywords or len(keywords) < 2:
                logger.warning("âš ï¸ No valid keywords, returning ALL recent invoices with images...")
                sql_fallback = text("""
                    SELECT *
                    FROM invoices
                    WHERE is_valid_invoice = true
                    AND image_url IS NOT NULL
                    ORDER BY created_at DESC
                    LIMIT :limit
                """)
                
                rows = db.execute(sql_fallback, {"limit": top_k}).fetchall()
            else:
                # Search in basic invoice fields only (NO embeddings)
                sql_fallback = text("""
                    SELECT *
                    FROM invoices
                    WHERE is_valid_invoice = true
                    AND image_url IS NOT NULL
                    AND (
                        LOWER(vendor) LIKE LOWER(:keyword_pattern)
                        OR LOWER(category::text) LIKE LOWER(:keyword_pattern)
                        OR LOWER(invoice_type) LIKE LOWER(:keyword_pattern)
                        OR LOWER(branch) LIKE LOWER(:keyword_pattern)
                        OR LOWER(invoice_number) LIKE LOWER(:keyword_pattern)
                    )
                    ORDER BY 
                        CASE 
                            WHEN LOWER(vendor) LIKE LOWER(:keyword_start) THEN 1
                            WHEN LOWER(vendor) LIKE LOWER(:keyword_pattern) THEN 2
                            ELSE 3
                        END,
                        created_at DESC
                    LIMIT :limit
                """)
                
                rows = db.execute(
                    sql_fallback, 
                    {
                        "keyword_pattern": f"%{keywords}%",
                        "keyword_start": f"{keywords}%",
                        "limit": top_k * 2  # Get more results for better matching
                    }
                ).fetchall()
            
            results = [serialize_for_json(dict(row._mapping)) for row in rows]
            logger.info(f"âœ… SQL Fallback returned {len(results)} results")
            
            if results:
                logger.info("ğŸ“‹ Top results:")
                for i, item in enumerate(results[:5], 1):
                    vendor = item.get('vendor', 'Unknown')
                    has_image = bool(item.get('image_url'))
                    logger.info(f"   {i}. {vendor} (image: {has_image})")
            else:
                logger.warning(f"âš ï¸ No results found for keywords: '{keywords}'")
            
            return results[:top_k]  # Return only top_k results
            
        except Exception as fallback_error:
            logger.error(f"âŒ SQL Fallback failed: {fallback_error}")
            import traceback
            logger.error(f"Stack trace: {traceback.format_exc()}")
        
        return []


def execute_hybrid(refined_query: str, db: Session) -> List[Dict]:
    """
    ğŸ”„ Execute hybrid approach: SQL first, then RAG
    
    Args:
        refined_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
        db: Database session
    
    Returns:
        Combined results from SQL and RAG
    """
    logger.info("ğŸ”„ Executing Hybrid (SQL + RAG)...")
    
    try:
        # Try SQL first
        sql_results = execute_deep_sql(refined_query, db)
        
        if sql_results and len(sql_results) > 0:
            logger.info(f"âœ… SQL found {len(sql_results)} results, using SQL results")
            return sql_results
        
        # Fallback to RAG if SQL returns nothing
        logger.info("âš ï¸ SQL returned no results, falling back to RAG...")
        rag_results = execute_rag(refined_query, db)
        
        logger.info(f"âœ… Hybrid returned {len(rag_results)} results (from RAG)")
        return rag_results
        
    except Exception as e:
        logger.error(f"âŒ Hybrid execution failed: {e}")
        return []


def execute_query(refined_query: str, decision: RouterDecision, db: Session) -> List[Dict]:
    """
    ğŸš€ Main executor - ALWAYS uses RAG/Embeddings with SQL fallback
    
    Args:
        refined_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
        decision: Router decision
        db: Database session
    
    Returns:
        List of results
    """
    logger.info(f"ğŸš€ Starting RAG Executor (embeddings-based search)...")
    
    if decision.mode == "none":
        logger.info("â„¹ï¸ Query is out of scope (mode: none)")
        return []
    
    # ALWAYS use RAG (embeddings + SQL fallback)
    return execute_rag(refined_query, db)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âœ… STAGE 4: Validator
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def validate_results(results: List[Dict], refined_query: str) -> bool:
    """
    âœ… Validate that results actually match the query
    
    Args:
        results: Results from executor
        refined_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
    
    Returns:
        True if results are valid and relevant, False otherwise
    """
    logger.info("âœ… Starting Validator Stage...")
    
    if not results or len(results) == 0:
        logger.warning("âš ï¸ No results to validate")
        return False
    
    logger.info(f"âœ… Validated {len(results)} results")
    return True

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ’¬ STAGE 5: Replier
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_reply(refined_query: str, results: List[Dict], decision: RouterDecision) -> str:
    """
    ğŸ’¬ Generate final reply in Arabic with friendly tone
    
    Args:
        refined_query: Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
        results: Results from executor
        decision: Router decision
    
    Returns:
        Final reply string in Arabic
    """
    logger.info("ğŸ’¬ Starting Replier Stage...")
    
    try:
        # Handle out of scope
        if decision.mode == "none":
            logger.info("â„¹ï¸ Query out of scope, returning generic reply")
            return "Ù‡Ø°Ø§ Ø®Ø§Ø±Ø¬ Ø§Ø®ØªØµØ§ØµÙŠØŒ Ø£Ù†Ø§ Ù…ØªØ®ØµØµ ÙÙ‚Ø· ÙÙŠ ØªØ­Ù„ÙŠÙ„ ÙÙˆØ§ØªÙŠØ±Ùƒ ğŸ’¡"
        
        # Handle no results
        if not results or len(results) == 0:
            logger.info("â„¹ï¸ No results found")
            return "Ù…Ø§ Ù„Ù‚ÙŠØª ÙÙˆØ§ØªÙŠØ± ØªØ·Ø§Ø¨Ù‚ Ø¨Ø­Ø«Ùƒ ğŸ˜”"
        
        # Generate reply based on results
        reply_prompt = f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙÙŠ Ù†Ø¸Ø§Ù… Ù…ÙÙÙÙˆÙ’ØªÙØ± Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ÙÙˆØ§ØªÙŠØ±.

**Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:**
"{refined_query}"

**Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø©:**
{json.dumps(serialize_for_json(results[:3]), ensure_ascii=False, indent=2)}

**Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø±Ø¯ (Ø§Ù„ØªØ²Ù… Ø¨Ù‡Ø§ Ø¨Ø¯Ù‚Ø©):**

1. **Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© (ÙƒÙ… Ø¹Ø¯Ø¯ØŒ ÙƒÙ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ):**
   - Ø±Ø¯ Ù…Ø®ØªØµØ± Ø¬Ø¯Ø§Ù‹: "Ø¹Ù†Ø¯Ùƒ X ÙÙˆØ§ØªÙŠØ± ğŸ“„"
   - Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙŠ ØªÙØ§ØµÙŠÙ„ ÙÙˆØ§ØªÙŠØ±!

2. **Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø¹Ù† ÙØ§ØªÙˆØ±Ø© Ù…Ø­Ø¯Ø¯Ø© Ø£Ùˆ Ø·Ù„Ø¨ ØµÙˆØ±Ø©:**
   - Ø±Ø¯ Ø¨Ø³ÙŠØ·: "Ù„Ù‚ÙŠØª ÙØ§ØªÙˆØ±Ø© [Ø§Ù„Ù…ØªØ¬Ø±] ğŸ§¾"
   - Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ù†Ø§Ùƒ ØµÙˆØ±: "Ù‡Ø°ÙŠ ØµÙˆØ±Ø© Ø§Ù„ÙØ§ØªÙˆØ±Ø© ğŸ“¸"
   - Ø£Ùˆ: "ØªÙ…Ø§Ù…! Ù‡Ø°Ù‡ ÙØ§ØªÙˆØ±Ø© [Ø§Ù„Ù…ØªØ¬Ø±] Ø¨Ù…Ø¨Ù„Øº [X] ï·¼"

3. **Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ© (Ø£Ø¹Ù„Ù‰ØŒ Ø£Ù‚Ù„):**
   - "Ø£Ø¹Ù„Ù‰ ÙØ§ØªÙˆØ±Ø© Ø¹Ù†Ø¯Ùƒ [X] ï·¼ Ù…Ù† [Ø§Ù„Ù…ØªØ¬Ø±] ğŸ’°"

4. **Ø¥Ø°Ø§ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬:**
   - "Ù…Ø§ Ù„Ù‚ÙŠØª ÙÙˆØ§ØªÙŠØ± Ø¨Ù‡Ø°Ø§ Ø§Ù„ÙˆØµÙ ğŸ˜”"

**Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ø±Ø¯:**
- Ø¹Ø±Ø¨ÙŠ ÙØµÙŠØ­ Ù…Ø¹ Ù„Ù‡Ø¬Ø© Ø³Ø¹ÙˆØ¯ÙŠØ© Ø®ÙÙŠÙØ©
- Ù…Ø®ØªØµØ± ÙˆÙˆØ§Ø¶Ø­ ÙˆÙ…Ø¨Ø§Ø´Ø±
- Ø§Ø³ØªØ®Ø¯Ù… emoji Ù…Ù†Ø§Ø³Ø¨
- Ø§Ù„ØµÙˆØ± ØªØ¸Ù‡Ø± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ØŒ Ù„Ø§ Ø¯Ø§Ø¹ÙŠ Ù„ØªÙØµÙŠÙ„

**Ø§Ù„Ø±Ø¯:**
"""
        
        response = client.chat.completions.create(
            model=LLM_MODEL,
                messages=[
                {
                    "role": "system",
                    "content": """Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙÙŠ Ù†Ø¸Ø§Ù… Ù…ÙÙÙÙˆÙ’ØªÙØ±.
Ø£Ø³Ù„ÙˆØ¨Ùƒ: Ø¹Ø±Ø¨ÙŠ ÙØµÙŠØ­ Ù…Ø¹ Ù„Ù‡Ø¬Ø© Ø³Ø¹ÙˆØ¯ÙŠØ© Ø®ÙÙŠÙØ©ØŒ Ù…Ø®ØªØµØ± ÙˆÙˆØ§Ø¶Ø­.
Ù„Ø§ ØªØ°ÙƒØ± Ø£ÙƒÙˆØ§Ø¯ Ø£Ùˆ JSONØŒ ÙÙ‚Ø· Ø±Ø¯ÙˆØ¯ Ø·Ø¨ÙŠØ¹ÙŠØ©."""
                },
                {"role": "user", "content": reply_prompt}
            ],
            temperature=0.7,
            max_tokens=300
        )
        
        final_reply = response.choices[0].message.content.strip()
        
        logger.info(f"âœ… Generated reply: {final_reply[:100]}...")
        return final_reply
        
    except Exception as e:
        logger.error(f"âŒ Replier Stage failed: {e}")
        return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ ØµÙŠØ§ØºØ© Ø§Ù„Ø±Ø¯ ğŸ˜”"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¯ Main Endpoint
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ChatRequest(BaseModel):
    """Chat request model"""
    message: str


@router.post("/ask")
async def chat_ask(request: ChatRequest, db: Session = Depends(get_db)):
    """
    ğŸ¯ Main Chat Endpoint
    
    Process user query through all stages:
    1. Refiner  - ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø³Ø¤Ø§Ù„
    2. Router   - ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    3. Executor - ØªÙ†ÙÙŠØ° Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
    4. Validator - Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    5. Replier  - ØµÙŠØ§ØºØ© Ø§Ù„Ø±Ø¯
    
    Args:
        request: ChatRequest with user message
        db: Database session
    
    Returns:
        JSON response with reply and data
    """
    logger.info("="*80)
    logger.info("ğŸ¯ NEW CHAT REQUEST")
    logger.info(f"ğŸ“ User Message: {request.message}")
    logger.info("="*80)
    
    try:
        user_query = request.message.strip()
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Stage 1: Refiner
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        refined_query = refine_user_query(user_query)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Stage 2: Router
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        decision = route_query(refined_query)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Stage 3: Executor
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        results = execute_query(refined_query, decision, db)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Stage 4: Validator
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        is_valid = validate_results(results, refined_query)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Stage 5: Replier
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        final_reply = generate_reply(refined_query, results, decision)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Format invoices for frontend
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        invoices_for_display = []
        if decision.show_images and results:
            for item in results:
                formatted = format_invoice_for_frontend(item)
                
                # Filter by requested vendor if specified
                if decision.requested_vendor:
                    item_vendor = (item.get("vendor") or "").lower()
                    vendor_filter = decision.requested_vendor.lower()
                    
                    if vendor_filter not in item_vendor:
                        continue
                
                if formatted.get("id") and formatted.get("vendor"):
                    invoices_for_display.append(formatted)
            
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Save to context
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        if invoices_for_display:
            context.add_context(
                intent=user_query,
                invoices=invoices_for_display[:3],
                mode=decision.mode
            )
            logger.info(f"ğŸ’¾ Saved {len(invoices_for_display[:3])} invoices to context")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Final Response
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info("="*80)
        logger.info(f"âœ… CHAT RESPONSE READY")
        logger.info(f"   Mode: {decision.mode}")
        logger.info(f"   Results: {len(results)}")
        logger.info(f"   Invoices to display: {len(invoices_for_display)}")
        logger.info(f"   Reply: {final_reply[:100]}...")
        logger.info("="*80)

        return {
            "reply": final_reply,
            "invoices": invoices_for_display if invoices_for_display else None,
            "mode": decision.mode,
            "result_count": len(results),
            "show_images": decision.show_images,
            "is_valid": is_valid,
            "refined_query": refined_query
        }

    except Exception as e:
        logger.error("="*80)
        logger.error(f"âŒ CHAT ERROR: {e}")
        logger.error("="*80)
        
        return {
            "reply": "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ùƒ ğŸ˜” Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.",
            "error": str(e),
            "mode": "error",
            "result_count": 0
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ” Additional Helper Endpoints
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.get("/context")
async def get_context():
    """Get current conversation context"""
    return {
        "last_intents": context.last_3_intents,
        "last_invoices_count": len(context.get_last_invoices()),
        "last_modes": context.last_3_modes
    }


@router.post("/context/clear")
async def clear_context():
    """Clear conversation context"""
    context.clear()
    logger.info("ğŸ—‘ï¸ Context cleared")
    return {"status": "Context cleared successfully"}


@router.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "service": "Ù…ÙÙÙÙˆÙ’ØªÙØ± Chat AI",
        "version": "2.0.0"
        }
